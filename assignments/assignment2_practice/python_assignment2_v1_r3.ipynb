{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2f6e33",
   "metadata": {},
   "source": [
    "# Programming and Tools for AI (/Online)\n",
    "# James McDermott, University of Galway, 2022\n",
    "# CT5132/CT5148\n",
    "# Assignment 2\n",
    "\n",
    "**Due**:\n",
    "\n",
    "* CT5132 midnight Friday 28 Oct (end of Week 8)\n",
    "* CT5148 midnight Sunday 30 Oct (end of Week 8)\n",
    "\n",
    "**Weight**: this is worth 25% of the module.\n",
    "\n",
    "**Groups**: you can work solo or in a group of two, as you prefer. You can not work together with another student you already worked with in any assignment in this module or any other. If working in a group, both students should submit and their submissions should be identical.\n",
    "\n",
    "**Plagiarism**: students are reminded of the University's policies on plagiarism. Code copied from the internet should be sourced with the URL in a comment. Students can discuss the assignment but must not look at each other's work (other than within a group). Some cases were reported to relevant authorities during Assignment 1.\n",
    "\n",
    "**Requirements**:\n",
    "\n",
    "* Add your name(s)/ID(s) in the next cell.\n",
    "* Write code in this notebook to pass the doctests and produce the images as directed.\n",
    "* Write new doctests. For each docstring below which contains doctests, you have to add one more doctest inside the same docstring, together with a line or two of explanation in your own words.\n",
    "* Submit your .ipynb file and nothing else. Don't type in the submission box.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "Do not change or delete any doctests, or insert lines above the docstrings, or change the doctest calls.\n",
    "\n",
    "When I receive your submission, I'll go to the Kernel menu and \"Restart and run all\", and I'll look at your code, your doctests, and your outputs. So, the last thing you should do before submitting is \"Restart and run all\" and check that every part runs correctly. (One thing that sometimes goes wrong in notebooks is that a piece of code relies on a variable or function which was previously defined but is now deleted but is still \"alive\" in the kernel's memory, so the notebook crashes when re-run.)\n",
    "\n",
    "Marks will be awarded for each of the 12 questions. Both correct outputs and code will be assessed. Images are not expected to match exactly, but doctests are.\n",
    "\n",
    "If you get stuck on any part, you should still be able to continue to other parts. If you can't see how to proceed in this case, please ask me.\n",
    "\n",
    "There are a lot of parts, so even if you don't get everything, you can still get a good mark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92c090",
   "metadata": {},
   "source": [
    "**Student ID(s)**: 20230033\n",
    "\n",
    "**Name(s)**: Jiarong Li\n",
    "\n",
    "**Declaration**: By submitting to Blackboard, I/we declare that I/we have not seen any work by other students on this assignment and have not shown my/our work to any others. I/we declare that we have not worked together on any previous assignment in this module or another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7ad993",
   "metadata": {},
   "source": [
    "# Clustering Sequences using $n$-grams\n",
    "\n",
    "In this assignment, we'll put together a clustering method specialised to sequence mining, in the style of Scikit-Learn. We'll use components from Scikit-Learn itself, Numpy, and Matplotlib.\n",
    "\n",
    "Usually when we do machine learning, we fit with numerical, rectangular data, so each sample is a feature vector. But sequences are a bit different. For a start, each sequence might be of different length. Also, commonalities between sequences might be mis-aligned, eg these two sequences are pretty similar:\n",
    "\n",
    "$(0, 0, 1, 4, 7, 0)$\n",
    "\n",
    "$(0, 1, 4, 7, 0, 1)$\n",
    "\n",
    "The approach we'll use is to count common subsequences of length $n$, ie $n$-grams. \n",
    "\n",
    "Many machine learning algorithms work fine even if we don't have feature vectors, but we have distances between points. \n",
    "\n",
    "We will use the $n$-gram counts to compute a measure of dissimilarity between any pair of sequences.\n",
    "\n",
    "In Scikit-Learn, several algorithms accept a keyword such as `metric=\"precomputed\"` or `affinity=\"precomputed\"`, which allows us to pass in the square matrix of distances instead of passing in the points themselves.\n",
    "\n",
    "This notebook will walk us through all the steps, with doctests and examples for each. Most of the code needed is based on something we've seen in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1daac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "assert sys.version_info >= (3, 7), \"This notebook requires Python 3.7+\"\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "import doctest\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da69160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 2, 0, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 2, 1, 1, 2, 1]\n",
      "[2, 1, 1, 3, 1, 2, 6, 6, 6, 1, 4, 6, 1, 3, 6, 1, 4, 5, 6, 3, 4, 6, 1, 3, 5, 4, 1, 3, 5, 2, 4, 6, 6, 6, 3, 6, 6, 4, 1, 5]\n",
      "[4, 3, 2, 2, 4, 3, 4, 4, 3, 3, 3, 4, 2, 2, 3, 2, 4, 2, 3, 3, 2, 2, 4, 4, 3, 3, 3, 2, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# here we construct 10 fake sequences from each of 3 methods\n",
    "X = [[random.randrange(0, 3) for _ in range(40)] for _ in range(50)] + \\\n",
    "    [[random.randrange(1, 7) for _ in range(40)] for _ in range(50)] + \\\n",
    "    [[random.randrange(2, 5) for _ in range(30)] for _ in range(50)]\n",
    "print(X[0]) # take a look at one example from each method\n",
    "print(X[50])\n",
    "print(X[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19fe7b6",
   "metadata": {},
   "source": [
    "**Question 1**. Suppose we have a sequence of integers, `x`, eg `x = [0, 1, 4, 0, 1, 4, 7, 0, 1, 4]`. We immediately see that there are some common subsequences: eg `[0, 1, 4]` occurs three times.\n",
    "\n",
    "Write a function `count_ngrams` which extracts all *n-grams*, ie all subsequences of length `n`, and returns their number of occurrences in a `Counter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2dd930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngrams(x, n):\n",
    "    '''\n",
    "The input can be a list:\n",
    ">>> count_ngrams([0, 1, 4, 0, 1, 4, 7, 0, 1, 4], 3)\n",
    "Counter({(0, 1, 4): 3,\n",
    "         (1, 4, 0): 1,\n",
    "         (4, 0, 1): 1,\n",
    "         (1, 4, 7): 1,\n",
    "         (4, 7, 0): 1,\n",
    "         (7, 0, 1): 1})\n",
    "         \n",
    "It can be a tuple:\n",
    ">>> count_ngrams((0, 1, 4, 0, 1, 4, 7, 0, 1, 4), 5)\n",
    "Counter({(0, 1, 4, 0, 1): 1, \n",
    "         (1, 4, 0, 1, 4): 1, \n",
    "         (4, 0, 1, 4, 7): 1, \n",
    "         (0, 1, 4, 7, 0): 1, \n",
    "         (1, 4, 7, 0, 1): 1, \n",
    "         (4, 7, 0, 1, 4): 1})\n",
    "         \n",
    "It can be empty:         \n",
    ">>> count_ngrams([], 3)\n",
    "Counter()\n",
    "\n",
    "It can even be a string:\n",
    ">>> count_ngrams(\"abcdabcdefacd\", 3)\n",
    "Counter({('a', 'b', 'c'): 2, ('b', 'c', 'd'): 2, ('c', 'd', 'a'): 1, \n",
    "         ('d', 'a', 'b'): 1, ('c', 'd', 'e'): 1, ('d', 'e', 'f'): 1, \n",
    "         ('e', 'f', 'a'): 1, ('f', 'a', 'c'): 1, ('a', 'c', 'd'): 1})\n",
    "         \n",
    "The input can be a string:\n",
    ">>> count_ngrams(\"asd345fgh678\", 3)\n",
    "Counter({('a', 's', 'd'): 1, ('s', 'd', '3'): 1, ('d', '3', '4'): 1,\n",
    "         ('3', '4', '5'): 1, ('4', '5', 'f'): 1, ('5', 'f', 'g'): 1,\n",
    "         ('f', 'g', 'h'): 1, ('g', 'h', '6'): 1, ('h', '6', '7'): 1,\n",
    "         ('6', '7', '8'): 1})\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # my code is 1 line\n",
    "    subsequences = []    \n",
    "    for i in list(range(len(x) - n + 1)):\n",
    "        subsequences.append(x[i:i+n])\n",
    "\n",
    "    return Counter(map(tuple, subsequences)) # map() here convert list object to a tuple \n",
    "                                             # and return a literable map object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d694d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    count_ngrams([0, 1, 4, 0, 1, 4, 7, 0, 1, 4], 3)\n",
      "Expecting:\n",
      "    Counter({(0, 1, 4): 3,\n",
      "             (1, 4, 0): 1,\n",
      "             (4, 0, 1): 1,\n",
      "             (1, 4, 7): 1,\n",
      "             (4, 7, 0): 1,\n",
      "             (7, 0, 1): 1})\n",
      "ok\n",
      "Trying:\n",
      "    count_ngrams((0, 1, 4, 0, 1, 4, 7, 0, 1, 4), 5)\n",
      "Expecting:\n",
      "    Counter({(0, 1, 4, 0, 1): 1, \n",
      "             (1, 4, 0, 1, 4): 1, \n",
      "             (4, 0, 1, 4, 7): 1, \n",
      "             (0, 1, 4, 7, 0): 1, \n",
      "             (1, 4, 7, 0, 1): 1, \n",
      "             (4, 7, 0, 1, 4): 1})\n",
      "ok\n",
      "Trying:\n",
      "    count_ngrams([], 3)\n",
      "Expecting:\n",
      "    Counter()\n",
      "ok\n",
      "Trying:\n",
      "    count_ngrams(\"abcdabcdefacd\", 3)\n",
      "Expecting:\n",
      "    Counter({('a', 'b', 'c'): 2, ('b', 'c', 'd'): 2, ('c', 'd', 'a'): 1, \n",
      "             ('d', 'a', 'b'): 1, ('c', 'd', 'e'): 1, ('d', 'e', 'f'): 1, \n",
      "             ('e', 'f', 'a'): 1, ('f', 'a', 'c'): 1, ('a', 'c', 'd'): 1})\n",
      "ok\n",
      "Trying:\n",
      "    count_ngrams(\"asd345fgh678\", 3)\n",
      "Expecting:\n",
      "    Counter({('a', 's', 'd'): 1, ('s', 'd', '3'): 1, ('d', '3', '4'): 1,\n",
      "             ('3', '4', '5'): 1, ('4', '5', 'f'): 1, ('5', 'f', 'g'): 1,\n",
      "             ('f', 'g', 'h'): 1, ('g', 'h', '6'): 1, ('h', '6', '7'): 1,\n",
      "             ('6', '7', '8'): 1})\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(count_ngrams, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878028a",
   "metadata": {},
   "source": [
    "**Question 2**. Suppose we have a list of sequences, `X`. Write a function which gets the ngrams for each sequence in `X`. Of course it should just use our `count_ngrams`. Notice that `X` could be *ragged*, ie not every sequence in `X` has to be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d653df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngrams_multi(X, n):\n",
    "    '''\n",
    ">>> count_ngrams_multi([[0, 1, 4, 0, 1, 4, 7, 0, 1, 4],\n",
    "...                     [4, 5, 6, 4, 5, 6],\n",
    "...                     [1, 5, 9, 5, 1]], 3)\n",
    "[Counter({(0, 1, 4): 3, (1, 4, 0): 1, (4, 0, 1): 1, \n",
    "          (1, 4, 7): 1, (4, 7, 0): 1, (7, 0, 1): 1}), \n",
    " Counter({(4, 5, 6): 2, (5, 6, 4): 1, (6, 4, 5): 1}), \n",
    " Counter({(1, 5, 9): 1, (5, 9, 5): 1, (9, 5, 1): 1})]\n",
    ">>> count_ngrams_multi([[]], 3)\n",
    "[Counter()]\n",
    "\n",
    "Some sequences in X can be different length and can be a string and a list\n",
    ">>> count_ngrams_multi([\"abcdabcdefacd\",\n",
    "...                     [4, 5, 6, 4, 5, 6],\n",
    "...                     [1, 5, 9, 5, 1]], 3)\n",
    "[Counter({('a', 'b', 'c'): 2,\n",
    "          ('b', 'c', 'd'): 2,\n",
    "          ('c', 'd', 'a'): 1,\n",
    "          ('d', 'a', 'b'): 1,\n",
    "          ('c', 'd', 'e'): 1,\n",
    "          ('d', 'e', 'f'): 1,\n",
    "          ('e', 'f', 'a'): 1,\n",
    "          ('f', 'a', 'c'): 1,\n",
    "          ('a', 'c', 'd'): 1}),\n",
    " Counter({(4, 5, 6): 2, (5, 6, 4): 1, (6, 4, 5): 1}),\n",
    " Counter({(1, 5, 9): 1, (5, 9, 5): 1, (9, 5, 1): 1})]\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # my code is 1 line\n",
    "    return [count_ngrams(x, n) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ff1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    count_ngrams_multi([[0, 1, 4, 0, 1, 4, 7, 0, 1, 4],\n",
      "                        [4, 5, 6, 4, 5, 6],\n",
      "                        [1, 5, 9, 5, 1]], 3)\n",
      "Expecting:\n",
      "    [Counter({(0, 1, 4): 3, (1, 4, 0): 1, (4, 0, 1): 1, \n",
      "              (1, 4, 7): 1, (4, 7, 0): 1, (7, 0, 1): 1}), \n",
      "     Counter({(4, 5, 6): 2, (5, 6, 4): 1, (6, 4, 5): 1}), \n",
      "     Counter({(1, 5, 9): 1, (5, 9, 5): 1, (9, 5, 1): 1})]\n",
      "ok\n",
      "Trying:\n",
      "    count_ngrams_multi([[]], 3)\n",
      "Expecting:\n",
      "    [Counter()]\n",
      "ok\n",
      "Trying:\n",
      "    count_ngrams_multi([\"abcdabcdefacd\",\n",
      "                        [4, 5, 6, 4, 5, 6],\n",
      "                        [1, 5, 9, 5, 1]], 3)\n",
      "Expecting:\n",
      "    [Counter({('a', 'b', 'c'): 2,\n",
      "              ('b', 'c', 'd'): 2,\n",
      "              ('c', 'd', 'a'): 1,\n",
      "              ('d', 'a', 'b'): 1,\n",
      "              ('c', 'd', 'e'): 1,\n",
      "              ('d', 'e', 'f'): 1,\n",
      "              ('e', 'f', 'a'): 1,\n",
      "              ('f', 'a', 'c'): 1,\n",
      "              ('a', 'c', 'd'): 1}),\n",
      "     Counter({(4, 5, 6): 2, (5, 6, 4): 1, (6, 4, 5): 1}),\n",
      "     Counter({(1, 5, 9): 1, (5, 9, 5): 1, (9, 5, 1): 1})]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# This runs our count_ngrams_multi doctests.\n",
    "doctest.run_docstring_examples(count_ngrams_multi, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bfa93",
   "metadata": {},
   "source": [
    "**Question 3**. We're going to need a helper function `counter_total` which measures the \"total size\" of a `Counter` by counting the total of its individual counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69faaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_total(c):\n",
    "    '''\n",
    "    Sum of the counts in a counter c\n",
    "    \n",
    "    If you have Python 3.10+, this is available directly as c.total().\n",
    "    \n",
    "    >>> counter_total(Counter())\n",
    "    0\n",
    "    >>> counter_total(Counter({'a': 1, 'b': 3}))\n",
    "    4\n",
    "    \n",
    "    The input can be a counter with multiple dicts\n",
    "    >>> counter_total(Counter({(0, 1, 4): 3, (1, 4, 0): 1, (4, 0, 1): 1, (1, 4, 7): 1, (4, 7, 0): 1, (7, 0, 1): 1}))\n",
    "    8\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # my code is 1 line\n",
    "    return sum(c.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c513f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    counter_total(Counter())\n",
      "Expecting:\n",
      "    0\n",
      "ok\n",
      "Trying:\n",
      "    counter_total(Counter({'a': 1, 'b': 3}))\n",
      "Expecting:\n",
      "    4\n",
      "ok\n",
      "Trying:\n",
      "    counter_total(Counter({(0, 1, 4): 3, (1, 4, 0): 1, (4, 0, 1): 1, (1, 4, 7): 1, (4, 7, 0): 1, (7, 0, 1): 1}))\n",
      "Expecting:\n",
      "    8\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(counter_total, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbac596",
   "metadata": {},
   "source": [
    "**Question 4**.\n",
    "\n",
    "Next, we want to measure the *dissimilarity* between two sequences, `X` and `Y`.  \n",
    "\n",
    "Since we already have a method for representing a sequence as a `Counter` of n-grams, we only need a method for measuring the dissimilarity of two `Counter`s, $A$ and $B$. One main approach is the *Jaccard dissimilarity*. It's defined as:\n",
    "\n",
    "$$\\mathrm{JD}(A, B) = 1 - \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "(Source: https://en.wikipedia.org/wiki/Jaccard_index.)\n",
    "\n",
    "In other words, $\\mathrm{JD}$ is low (dissimilarity low => similarity high) if there are many $n$-grams in common between `X` and `Y`. \n",
    "\n",
    "By the way, if you Google for \"python jaccard distance\" you'll find a lot of results which are not what we want, so be careful.\n",
    "\n",
    "To calculate intersection and union on `Counter` objects we can use `&` and `|` operators, and the result is a new `Counter`. After that we can use our `counter_total` to get the size `| |`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9abd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JD(A, B):\n",
    "    '''Jaccard dissimilarity on multisets, represented by Counters.\n",
    "    \n",
    "    Two are identical:\n",
    "    >>> JD(Counter({0, 1, 2, 3}), Counter({0, 1, 2, 3}))\n",
    "    0.0\n",
    "    \n",
    "    Two are similar:\n",
    "    >>> JD(Counter([0, 0, 0, 1, 1, 2, 3]), Counter([0, 0, 0, 1, 1, 2, 4]))\n",
    "    0.25\n",
    "    \n",
    "    Two are totally different:\n",
    "    >>> JD(Counter({0, 1, 2, 3}), Counter({10, 11, 12, 13}))\n",
    "    1.0\n",
    "    \n",
    "    Two are in different length:\n",
    "    >>> JD(Counter([0, 0, 0]), Counter([0, 0, 0, 1, 1, 2, 4]))\n",
    "    0.5714285714285714\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # my code is 1 line\n",
    "    \n",
    "    return (1 - (counter_total(A & B) / counter_total(A | B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c37878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    JD(Counter({0, 1, 2, 3}), Counter({0, 1, 2, 3}))\n",
      "Expecting:\n",
      "    0.0\n",
      "ok\n",
      "Trying:\n",
      "    JD(Counter([0, 0, 0, 1, 1, 2, 3]), Counter([0, 0, 0, 1, 1, 2, 4]))\n",
      "Expecting:\n",
      "    0.25\n",
      "ok\n",
      "Trying:\n",
      "    JD(Counter({0, 1, 2, 3}), Counter({10, 11, 12, 13}))\n",
      "Expecting:\n",
      "    1.0\n",
      "ok\n",
      "Trying:\n",
      "    JD(Counter([0, 0, 0]), Counter([0, 0, 0, 1, 1, 2, 4]))\n",
      "Expecting:\n",
      "    0.5714285714285714\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(JD, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028ecb7",
   "metadata": {},
   "source": [
    "**Question 5**. As explained earlier, we need a function to precompute the distances between pairs of sequences and store them in an array. The main use of this is to calculate the pairwise distances between all pairs of n-grams derived from the training data (which is a list of sequences). The result of this is a square distance matrix, which will have zero on the diagonal. \n",
    "\n",
    "However, we can make our function slightly more general. If we write it to accept *two* lists of ngrams, and return a rectangular distance matrix then it will be useful in more situations. We can still use it for the original purpose by passing the same list twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0172b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix(ngrams1, ngrams2):\n",
    "    \"\"\"\n",
    "    If ngrams1 and ngrams2 are the same we get a square matrix:\n",
    "    >>> distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
    "    ...                 count_ngrams_multi(['abcd', 'abc', 'acde'], 2)).shape == (3, 3)\n",
    "    True\n",
    "\n",
    "    And we get zeros on the diagonal, because JD(A, A) == 0 for any A:\n",
    "    >>> distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
    "    ...                 count_ngrams_multi(['abcd', 'abc', 'acde'], 2)).diagonal()\n",
    "    array([0., 0., 0.])\n",
    "\n",
    "    If ngrams1 and ngrams2 are different lengths we get a rectangular (not square) matrix:\n",
    "    >>> distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
    "    ...                 count_ngrams_multi(['abcd', 'abc'        ], 2)).shape == (3, 2)\n",
    "    True\n",
    "    \n",
    "    We print out the distance matrix of ngrams1 and ngrams2 with different length.\n",
    "    >>> print(distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
    "    ...                       count_ngrams_multi(['abcd', 'abc'        ], 2)))\n",
    "    [[0.         0.33333333]\n",
    "    [0.33333333 0.        ]\n",
    "    [0.8        1.        ]]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # my code is 5 lines\n",
    "    \n",
    "    dis_matrix = np.zeros((len(ngrams1), len(ngrams2))) # We first create an array with zeros fill inside\n",
    "    \n",
    "    for i in range(len(ngrams1)): # we use i and ngrams1 represent row and use j and ngrams2 represents column.\n",
    "        for j in range(len(ngrams2)):\n",
    "            dis_matrix[i][j] = JD(ngrams1[i], ngrams2[j])\n",
    "    \n",
    "    return dis_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1d6af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
      "                    count_ngrams_multi(['abcd', 'abc', 'acde'], 2)).shape == (3, 3)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
      "                    count_ngrams_multi(['abcd', 'abc', 'acde'], 2)).diagonal()\n",
      "Expecting:\n",
      "    array([0., 0., 0.])\n",
      "ok\n",
      "Trying:\n",
      "    distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
      "                    count_ngrams_multi(['abcd', 'abc'        ], 2)).shape == (3, 2)\n",
      "Expecting:\n",
      "    True\n",
      "ok\n",
      "Trying:\n",
      "    print(distance_matrix(count_ngrams_multi(['abcd', 'abc', 'acde'], 2), \n",
      "                          count_ngrams_multi(['abcd', 'abc'        ], 2)))\n",
      "Expecting:\n",
      "    [[0.         0.33333333]\n",
      "    [0.33333333 0.        ]\n",
      "    [0.8        1.        ]]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(distance_matrix, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8d01a",
   "metadata": {},
   "source": [
    "**Question 6**. We need another helper function which calculates the *cluster score*. \n",
    "It will be similar to the $k$-means objective mentioned in lectures but not identical. We define the \n",
    "cluster score as 1 minus the normalised sum of intra-cluster distances. That is, we \n",
    "take all the points in a particular cluster and sum all the distances between them.\n",
    "Sum that over all clusters. Normalise that by dividing by the sum of distances \n",
    "between *all* points (regardless of cluster). The result is in [0, 1], of course. It's 0 if\n",
    "the points within each cluster are identical. It's larger if not. Finally, take 1\n",
    "minus that, so that higher is better. So 1 is the perfect score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d120529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_score(D, labels):\n",
    "    \"\"\"\n",
    "    Calculate a clustering score, defined as the 1 minus the\n",
    "    normalised sum of intra-cluster distances. The result is in\n",
    "    [0, 1], where higher is better.\n",
    "    \n",
    "    Here we see two clusters of two points each and in each cluster, and\n",
    "    the points are at zero distance from each other,\n",
    "    so we get a perfect score of 1.0\n",
    "    >>> cluster_score(np.array([[0, 0, 1, 1], \n",
    "    ...                         [0, 0, 1, 1],\n",
    "    ...                         [1, 1, 0, 0], \n",
    "    ...                         [1, 1, 0, 0]]), \n",
    "    ...               [0, 0, 1, 1])\n",
    "    1.0\n",
    "    \n",
    "    Again, two clusters of two points each, but\n",
    "    this time they are clustered badly! Nearby points are in\n",
    "    different clusters.\n",
    "    >>> cluster_score(np.array([[0, 0, 1, 1], \n",
    "    ...                         [0, 0, 1, 1],\n",
    "    ...                         [1, 1, 0, 0], \n",
    "    ...                         [1, 1, 0, 0]]), \n",
    "    ...               [0, 1, 0, 1])\n",
    "    0.5\n",
    "    \n",
    "    Again, two clusters, but more realistic:\n",
    "    >>> round(cluster_score(np.array([[0, 1, 7, 8], \n",
    "    ...                               [1, 0, 6, 5],\n",
    "    ...                               [7, 6, 0, 1], \n",
    "    ...                               [8, 5, 1, 0]]), \n",
    "    ...                     [0, 0, 1, 1]), 3)\n",
    "    0.929\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # my code is 5 lines\n",
    "    \n",
    "    clusters_dict = dict()\n",
    "\n",
    "    for i in range(len(labels)): # We sort the points with same labels and store them in a dictionary.\n",
    "        if labels[i] in clusters_dict: \n",
    "            clusters_dict[labels[i]].append(D[i])\n",
    "        else:\n",
    "            clusters_dict[labels[i]] = [D[i]]\n",
    "    \n",
    "   \n",
    "    dis_cs = sum(abs(clusters_dict[0][0] - clusters_dict[0][1])) + sum(abs(clusters_dict[1][0] - clusters_dict[1][1])) + sum(abs(clusters_dict[0][1] - clusters_dict[0][0])) + + sum(abs(clusters_dict[1][1] - clusters_dict[1][0]))\n",
    "    #print(dis_cs)\n",
    "    \n",
    "    dis_total = 0\n",
    "    for i in range(len(D)):\n",
    "        for j in range(len(D)):\n",
    "            dis_total += sum(abs(D[i] - D[j]))\n",
    "            #print(i, j, d_total)\n",
    "    \n",
    "    score = 1 - dis_cs / dis_total\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba38a687-c916-4997-b3b9-514810f3142b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056603773584906"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_score(np.array([[0, 1, 7, 8], \n",
    "                        [1, 0, 6, 5],\n",
    "                        [7, 6, 0, 1], \n",
    "                        [8, 5, 1, 0]]), \n",
    "              [0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49509f92-e6c6-4755-a914-5e39c6b05c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.464101615137754\n",
      "54.26644398006058\n",
      "0.8993097536085936\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "a = [0, 1, 7, 8]\n",
    "b = [1, 0, 6, 5]\n",
    "c = [7, 6, 0, 1]\n",
    "d = [8, 5, 1, 0]\n",
    "'''\n",
    "\n",
    "e = np.array([[0, 1, 7, 8], \n",
    "              [1, 0, 6, 5],\n",
    "              [7, 6, 0, 1], \n",
    "              [8, 5, 1, 0]])\n",
    "\n",
    "\n",
    "# take all the points (a, b) in cluster 0, and sum all the distance dis(a, b)\n",
    "\n",
    "# manhattan\n",
    "#dis_c = sum(np.square(e[0]-e[1])+np.square(e[2]-e[3]))\n",
    "#print(sum(np.square(e[2]-e[3])))\n",
    "\n",
    "#dis_all = sum(np.square(e[0] - e[1] - e[2] - e[3]))\n",
    "#print(dis_all)\n",
    "#print(1 - dis_c / dis_all)\n",
    "\n",
    "# euclidean\n",
    "dis_c = np.linalg.norm(e[0]-e[1]) + np.linalg.norm(e[2]-e[3])\n",
    "dis_all = dis_c + np.linalg.norm(e[0]-e[2]) + np.linalg.norm(e[0]-e[3]) + np.linalg.norm(e[1]-e[2]) + np.linalg.norm(e[1]-e[3])\n",
    "\n",
    "print(dis_c)\n",
    "print(dis_all)\n",
    "print(1 - dis_c / dis_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e7055-f841-403e-9dba-be3de67842c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2edd78b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    cluster_score(np.array([[0, 0, 1, 1], \n",
      "                            [0, 0, 1, 1],\n",
      "                            [1, 1, 0, 0], \n",
      "                            [1, 1, 0, 0]]), \n",
      "                  [0, 0, 1, 1])\n",
      "Expecting:\n",
      "    1.0\n",
      "ok\n",
      "Trying:\n",
      "    cluster_score(np.array([[0, 0, 1, 1], \n",
      "                            [0, 0, 1, 1],\n",
      "                            [1, 1, 0, 0], \n",
      "                            [1, 1, 0, 0]]), \n",
      "                  [0, 1, 0, 1])\n",
      "Expecting:\n",
      "    0.5\n",
      "ok\n",
      "Trying:\n",
      "    round(cluster_score(np.array([[0, 1, 7, 8], \n",
      "                                  [1, 0, 6, 5],\n",
      "                                  [7, 6, 0, 1], \n",
      "                                  [8, 5, 1, 0]]), \n",
      "                        [0, 0, 1, 1]), 3)\n",
      "Expecting:\n",
      "    0.929\n",
      "**********************************************************************\n",
      "File \"__main__\", line 28, in NoName\n",
      "Failed example:\n",
      "    round(cluster_score(np.array([[0, 1, 7, 8], \n",
      "                                  [1, 0, 6, 5],\n",
      "                                  [7, 6, 0, 1], \n",
      "                                  [8, 5, 1, 0]]), \n",
      "                        [0, 0, 1, 1]), 3)\n",
      "Expected:\n",
      "    0.929\n",
      "Got:\n",
      "    0.906\n"
     ]
    }
   ],
   "source": [
    "doctest.run_docstring_examples(cluster_score, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14018ce1",
   "metadata": {},
   "source": [
    "**Question 7**. Now, we're ready to put everything together. Create a class `NGramsKClusters` which inherits from `BaseEstimator` and `ClusterMixin`. This is analogous to the nearest-neighbours class we created when studying the Scikit-Learn API.\n",
    "\n",
    "It should have an `__init__` function which stores the values of $n$ and $k$. It should have a `fit` method, where the input `X` is a list of sequences. In `fit` we should precompute the distance matrix.\n",
    "\n",
    "To actually do the clustering in `fit`, we should use the Scikit-Learn `AgglomerativeClustering` method. We should pass it the arguments `linkage=\"average\"` and `affinity=\"precomputed\"`, but we don't need to understand the details here.\n",
    "\n",
    "Inside `fit`, our class should store the $n$-grams `ngrams_`, the distance matrix `distances_`, the labels found by AgglomerativeClustering `labels_`, and the clustering score `score_`. \n",
    "\n",
    "The function `fit_predict` will be supplied by the API. We don't have to write it. Behind the scenes it will call `fit` and immediately return the cluster label for each point in `X`. This is useful for clustering, because typically our only goal is to get cluster labels for the training data, ie we don't later on want to predict with any other `X`.\n",
    "\n",
    "However in our case, we will also write `predict`. The input to this is a new `X` and for each sequence in that `X` we should find the label of the nearest sequence in our training data. This can use our existing `distances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8810814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramsKClusters(BaseEstimator, ClusterMixin):\n",
    "    \"\"\"\n",
    "    >>> NGramsKClusters(n_clusters=2, ngram_len=3)\n",
    "    NGramsKClusters(n_clusters=2, ngram_len=3)\n",
    "\n",
    "    Don't forget, fit() should return self:\n",
    "    >>> NGramsKClusters(n_clusters=2, ngram_len=3).fit(X)\n",
    "    NGramsKClusters(n_clusters=2, ngram_len=3)\n",
    "    \n",
    "    If we fit with 2 clusters the output should be 0's and 1's\n",
    "    >>> set(NGramsKClusters(n_clusters=2, ngram_len=3).fit_predict(X))\n",
    "    {0, 1}\n",
    "\n",
    "    If we fit with 2 clusters the output should be 0's and 1's and 2's\n",
    "    >>> set(NGramsKClusters(n_clusters=3, ngram_len=3).fit_predict(X))\n",
    "    {0, 1, 2}\n",
    "\n",
    "    After fitting, the object should have various trailing-underscore values:\n",
    "    >>> nk = NGramsKClusters(n_clusters=2, ngram_len=3).fit(X)\n",
    "    >>> all(hasattr(nk, name)\n",
    "    ...     for name in ['ngrams_', 'labels_', 'score_', 'distances_'])\n",
    "    True\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # my code is ~20 lines\n",
    "    \n",
    "    # It should have an __init__ function which stores the values of n and k. \n",
    "    def __init__(self, n_clusters, ngram_len):\n",
    "        pass\n",
    "    \n",
    "    # It should have a fit method, where the input X is a list of sequences. \n",
    "    # In fit we should precompute the distance matrix. distance_matrix(ngrams1, ngrams2)\n",
    "    def fit(self, X):\n",
    "        clustering = AgglomerativeClustering(affinity='precomputed',\n",
    "                                             linkage=\"average\")\n",
    "        pass\n",
    "    \n",
    "        # Inside fit, our class should store the n-grams *ngrams_*, \n",
    "        # the distance matrix *distances_*, \n",
    "        # the labels found by AgglomerativeClustering *labels_*, \n",
    "        # and the clustering score *score_*.\n",
    "    \n",
    "    # The input to this is a new X \n",
    "    # and for each sequence in that X we should find the label of the nearest sequence in our training data. \n",
    "    # This can use our existing distances_.\n",
    "    def predict(self, X_new):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.run_docstring_examples(NGramsKClusters, globals(), verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47478e6e",
   "metadata": {},
   "source": [
    "**Question 8**. Now, let's use our class and the data it stores to evaluate.\n",
    "\n",
    "First, write a line of code to create the `NGramsKClusters` object with $n=3$ and $k=3$. Then fit it with `X`. Then print out the score. This doesn't need to be in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c65c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# my code is 3 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b62f3",
   "metadata": {},
   "source": [
    "**Question 9**. Next, here's a query sequence. Which cluster would it go into? Write a line or two of code to answer the question and to show that this result is \"correct\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968cb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [[0, 2, 1, 0, 1, 2, 0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# my code is ~ 6 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833622a",
   "metadata": {},
   "source": [
    "**Question 10**. Next let's visualise the results. First, use `imshow` to visualise the square distance matrix which has been saved by `fit`. We should get a result like this. It shows that the first 50 in X are all quite similar, and the last 50 in X are all quite similar, and the middle 50 are similar but slightly less so:\n",
    "\n",
    "![\"Title\"](NGramsKClusters_dissimilarity_matrix.png \"alt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# my code is 1 line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a19c29b",
   "metadata": {},
   "source": [
    "**Question 11**. Next, let's use $t$-SNE to visualise the data in 2D, with the labels shown as colour. This is similar to what we did under *Representation Learning*. Remember that we have `precomputed` distances. We should get an image something like this (it might be rotated or slightly different in other ways). It shows the three clusters clearly.\n",
    "\n",
    "![Image](NGramsKClusters_embedding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# my code is 4 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b13ee5",
   "metadata": {},
   "source": [
    "**Question 12**. Finally, let's check out how the score changes for different $k$. Again, this is similar to something we did under *Representation Learning*. We should end up with an image something like this:\n",
    "\n",
    "![Image](NGramsKClusters_cluster_score_by_k.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a42a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# my code is ~ 5 lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
