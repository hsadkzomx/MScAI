{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb44cd5-76a3-4464-b8aa-88fe4e814522",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67758bb3-815a-44d0-8fdf-59b6ca6df6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0f869-3cfe-452f-bfe3-8aa5cfe35162",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495696fb-3ff3-4e46-ae78-883620e1c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    # read file\n",
    "    file = pd.read_csv(file_name,\n",
    "                       sep=\"\\t\",\n",
    "                       skipinitialspace=True,\n",
    "                       skip_blank_lines=True,\n",
    "                       converters={'fire': str.strip})\n",
    "    \n",
    "    # replace newlines\n",
    "    file.replace('\\n','')\n",
    "\n",
    "    # convert txt file to csv\n",
    "    file.to_csv(\"wildfires.csv\", index=False)\n",
    "    \n",
    "    df = pd.read_csv(\"wildfires.csv\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06421f60-5035-4bc1-b3f4-515155787daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire</th>\n",
       "      <th>year</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>drought_code</th>\n",
       "      <th>buildup_index</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>2015</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>3.47</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>2010</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.17</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>2009</td>\n",
       "      <td>26</td>\n",
       "      <td>83</td>\n",
       "      <td>13.1</td>\n",
       "      <td>8.08</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>2017</td>\n",
       "      <td>25</td>\n",
       "      <td>87</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.18</td>\n",
       "      <td>2.42</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>2014</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.98</td>\n",
       "      <td>4.63</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>yes</td>\n",
       "      <td>2017</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>17.89</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>no</td>\n",
       "      <td>2017</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>4.4</td>\n",
       "      <td>8.74</td>\n",
       "      <td>6.52</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>no</td>\n",
       "      <td>2009</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>3.71</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>no</td>\n",
       "      <td>2016</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15.54</td>\n",
       "      <td>6.10</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>no</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.72</td>\n",
       "      <td>5.75</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fire  year  temp  humidity  rainfall  drought_code  buildup_index  day  \\\n",
       "0     no  2015    28        59       0.0          8.06           3.47    1   \n",
       "1     no  2010    30        61       1.3          8.17           4.03    2   \n",
       "2     no  2009    26        83      13.1          8.08           3.59    3   \n",
       "3     no  2017    25        87       2.5          7.18           2.42    4   \n",
       "4     no  2014    28        77       0.0         14.98           4.63    5   \n",
       "..   ...   ...   ...       ...       ...           ...            ...  ...   \n",
       "199  yes  2017    31        67       0.0         45.15          17.89   26   \n",
       "200   no  2017    29        89       4.4          8.74           6.52   27   \n",
       "201   no  2009    27        88       0.5          8.87           3.71   28   \n",
       "202   no  2016    25        56       0.1         15.54           6.10   29   \n",
       "203   no  2012    24        62       0.2         16.72           5.75   30   \n",
       "\n",
       "     month  wind_speed  \n",
       "0        6          19  \n",
       "1        6          13  \n",
       "2        6          22  \n",
       "3        6          15  \n",
       "4        6          18  \n",
       "..     ...         ...  \n",
       "199      9          15  \n",
       "200      9          15  \n",
       "201      9          30  \n",
       "202      9          20  \n",
       "203      9          17  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(\"wildfires(1).txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a3ed3-6b2a-4d07-be70-dab6aa13f8cd",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f313a21-bde4-47c7-b5d8-7462b0e0ef31",
   "metadata": {},
   "source": [
    "## Normalising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64388733-b916-4bc7-afe0-44091d19d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise data\n",
    "def normalisation(df):\n",
    "    \n",
    "    df_norm = df.copy()\n",
    "    \n",
    "    cols = [col for col in df_norm.columns]\n",
    "    \n",
    "    for col in cols[1:]:\n",
    "        x = np.array(df_norm[col])\n",
    "    \n",
    "        # Z-Normalisation: D ← (D - Mean) / StDev\n",
    "        #x = (x-np.mean(x))/np.std(x)\n",
    "    \n",
    "        # 0-1 Normalisation: D ← (D – Min) / (Max – Min)\n",
    "        x = (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    \n",
    "        df_norm[col] = x\n",
    "    \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171e0dd4-71b2-4398-8817-a1b27b6835ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire</th>\n",
       "      <th>year</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>drought_code</th>\n",
       "      <th>buildup_index</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.032114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.040478</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.779762</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.033906</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>0.049440</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177289</td>\n",
       "      <td>0.247498</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.007284</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>no</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.029762</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.035698</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>no</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.039034</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>no</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.044544</td>\n",
       "      <td>0.066169</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fire  year      temp  humidity  rainfall  drought_code  buildup_index  \\\n",
       "0     no   0.8  0.285714  0.535211  0.000000      0.004109       0.032114   \n",
       "1     no   0.3  0.380952  0.563380  0.077381      0.004622       0.040478   \n",
       "2     no   0.2  0.190476  0.873239  0.779762      0.004202       0.033906   \n",
       "3     no   1.0  0.142857  0.929577  0.148810      0.000000       0.016430   \n",
       "4     no   0.7  0.285714  0.788732  0.000000      0.036420       0.049440   \n",
       "..   ...   ...       ...       ...       ...           ...            ...   \n",
       "199  yes   1.0  0.428571  0.647887  0.000000      0.177289       0.247498   \n",
       "200   no   1.0  0.333333  0.957746  0.261905      0.007284       0.077670   \n",
       "201   no   0.2  0.238095  0.943662  0.029762      0.007891       0.035698   \n",
       "202   no   0.9  0.142857  0.492958  0.005952      0.039034       0.071397   \n",
       "203   no   0.5  0.095238  0.577465  0.011905      0.044544       0.066169   \n",
       "\n",
       "          day  month  wind_speed  \n",
       "0    0.000000    0.0    0.541667  \n",
       "1    0.033333    0.0    0.291667  \n",
       "2    0.066667    0.0    0.666667  \n",
       "3    0.100000    0.0    0.375000  \n",
       "4    0.133333    0.0    0.500000  \n",
       "..        ...    ...         ...  \n",
       "199  0.833333    1.0    0.375000  \n",
       "200  0.866667    1.0    0.375000  \n",
       "201  0.900000    1.0    1.000000  \n",
       "202  0.933333    1.0    0.583333  \n",
       "203  0.966667    1.0    0.458333  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = normalisation(df)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bc481d-e206-4389-9876-9e936db3012f",
   "metadata": {},
   "source": [
    "## Dividing dataset into testing set and remainder set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4885db9d-c3fb-43a5-9540-3cffcb9de990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly devide the file, 2/3 for training/validation and 1/3 for testing\n",
    "\n",
    "def divide_test_data(df, ratio_test=1.0/3.0):\n",
    "    \n",
    "    df_norm = normalisation(df)\n",
    "    \n",
    "    data_norm = df_norm.to_numpy()\n",
    "    \n",
    "    np.random.shuffle(data_norm) # shuffle the data before dividing \n",
    "    \n",
    "    test_data = data_norm[:int(len(data_norm)*ratio_test)]\n",
    "    remainder_data = data_norm[int(len(data_norm)*ratio_test):]\n",
    "    \n",
    "    return test_data, remainder_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7054cd-7fc2-476f-af07-95464139eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "136\n",
      "(136, 10)\n"
     ]
    }
   ],
   "source": [
    "test_data, remainder_data = divide_test_data(df_norm)\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(remainder_data))\n",
    "print(remainder_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ca705a-2536-4393-a1d2-95b0195d5671",
   "metadata": {},
   "source": [
    "## Dividing remainder set into training set and validation set\n",
    "\n",
    "#### Use the N-folders cross validation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d3316c-3ad9-4fc9-8bed-a7087b61ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly divide remainder_data into training sets and validation sets\n",
    "\n",
    "# divide remainder set into 4/5 for training\n",
    "def divide_train_val(remainder_data, ratio_train=4./5.):\n",
    "#def divide_train_val(remainder_data, N=5):\n",
    "    \n",
    "    np.random.shuffle(remainder_data) # shuffle the data before dividing \n",
    "\n",
    "    train_data = remainder_data[:int(len(remainder_data)*ratio_train)]\n",
    "    validation_data = remainder_data[int(len(remainder_data)*ratio_train):]\n",
    "    \n",
    "    #batches = []\n",
    "    \n",
    "    #for i in range(N):\n",
    "        #batches.append((i+1)*len(remainder_data))\n",
    "     #   print()\n",
    "    \n",
    "    return train_data, validation_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ac9d56-dab3-400f-985c-120c30ee2d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data = divide_train_val(remainder_data)\n",
    "print(len(train_data))\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837f19e4-2832-46a3-9907-61f1684d6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training/validation dataset\n",
    "\n",
    "def wildfires_dataloader(data):\n",
    "    \n",
    "    X = data[:,1:] # features\n",
    "    y = data[:,0] # labels\n",
    "    \n",
    "    # covert label from string to numerial format\n",
    "    yes_index = np.where(y==\"yes\")[0]\n",
    "    for i in yes_index:\n",
    "        #y[i] = np.array(([1],[0]))\n",
    "        y[i] = 1\n",
    "    \n",
    "    no_index = np.where(y==\"no\")[0]\n",
    "    for i in no_index:\n",
    "        #y[i] = np.array(([0],[1]))\n",
    "        y[i] = 0\n",
    "              \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac3bba42-b9df-45bf-b541-cc24c617bf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "108\n",
      "(108, 9)\n",
      "(108,)\n"
     ]
    }
   ],
   "source": [
    "X, y = wildfires_dataloader(train_data)\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1938e04f-b121-42d8-ae28-eb58a5952a6c",
   "metadata": {},
   "source": [
    "# Generate one perceptron layer\n",
    "\n",
    "Define the function set:\n",
    "\n",
    "$$\n",
    "y=f(x)\n",
    "$$\n",
    "denotes the output from the perceptron for an input vector $z$.\n",
    "\n",
    "And:\n",
    "\n",
    "$$\n",
    "y=X_{j,i}\\times w_{i} + b_{j}\n",
    "$$\n",
    "\n",
    "where $x_{j,i}$ represents the value of the $ith$ feature of the $jth$ training input vector, $w_{i}$ denoted the the $ith$ value in the weight vector, and $b_{j}$ represents the $jth$ value in the bias vector.\n",
    "\n",
    "$$\n",
    "y = f(x) = \\sigma(W^{L}... \\sigma(W^2\\times \\sigma(W^{1}\\times x + b^{1})+b^{2})...+b^{L})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641ebc75-5a97-4a20-8d19-205f6cbcdda1",
   "metadata": {},
   "source": [
    "#### techiniques for random initialising weight matrix\n",
    "\n",
    "$$\n",
    "W^{L}=np.random.randn(size_{L}, size_{L-1})*np.sqrt(1/size_{L-1})\n",
    "$$\n",
    "\n",
    "Xavier initialization.\n",
    "\n",
    "ref: https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78\n",
    "\n",
    "#### weight initialisation for different activation function\n",
    "\n",
    "ref: https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/weight_initialization_activation_functions/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a4197-9385-4b90-945e-1d1ebd6bd1e3",
   "metadata": {},
   "source": [
    "#### technique of calculating Root Mean Squared Error\n",
    "\n",
    "$$\n",
    "RMSD=\\sqrt{\\frac{\\sum_{n=1}^{N}(\\hat{y_{n}}-y_{n})^2}{N}}\n",
    "$$\n",
    "\n",
    "\n",
    "#### technique of calculating cross entropy\n",
    "$$\n",
    "C(y,\\hat{y})= -\\sum_{i=1}^{2}(\\hat{y_{i}}\\times \\log_{2}y_{i})=-\\hat{y_{1}}\\times \\log_{2}y_{1}-\\hat{y_{2}}\\times \\log_{2}y_{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f49ffb-3a53-4c16-9b07-ea6bc32e2d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1)\n",
      "-0.8236358218357203\n"
     ]
    }
   ],
   "source": [
    "lr=0.0001  # learning rate\n",
    "\n",
    "# randomly initialise parameters for each layer\n",
    "# we design one perceptron first\n",
    "\n",
    "W = np.random.randn(len(X[1]), 1)\n",
    "b = np.random.randn()\n",
    "\n",
    "print(W.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efee9fb-97d6-45a5-a3f0-4bea1b10c4d7",
   "metadata": {},
   "source": [
    "### One Perceptron\n",
    "\n",
    "$$\n",
    "y_{pred}=x\\times W + b \n",
    "$$\n",
    "\n",
    "cost:\n",
    "$$\n",
    "c^1 = (y_{truth} - y_{pred})^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial c}{\\partial w} = \\frac{\\partial z}{\\partial w}\\times \\frac{\\partial c}{\\partial z}\n",
    "$$\n",
    "\n",
    "### If we have one perceptron with an sigmpid function\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_{pred}=\\sigma(x\\times W + b)\n",
    "$$\n",
    "\n",
    "cost:\n",
    "$$\n",
    "c^1 = (y_{truth} - y_{pred})^2\n",
    "$$\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial c}{\\partial w} \\\\\n",
    "&= \\frac{\\partial z}{\\partial w}\\times \\frac{\\partial c}{\\partial z} \\\\\n",
    "&= forward pass \\times backward pass \\\\\n",
    "&= \\frac{\\partial z}{\\partial w}\\times \\frac{\\partial a}{\\partial z}\\times \\frac{c}{a} \\\\\n",
    "&= input(eg. x1, x2,...)\\times \\sigma'(z)\\times \\frac{\\partial z}{\\partial a}\n",
    "\\end{align}\n",
    "\n",
    "However, $\\sigma'(z)$ is a constant. Therefore the derivate of one perceptron and one perceptron with sigmoind function is the same.\n",
    "\n",
    "\\begin{align}\n",
    "\\sigma'(z)\n",
    "&=\\frac{e^{-z}}{(1+e^{-z})^{2}} \\\\\n",
    "&=\\frac{1}{1+e^{-z}}\\times (1-\\frac{1}{1+e^{-z}}) \\\\\n",
    "&=\\sigma(z)\\times (1-\\sigma(z))\n",
    "\\end{align}\n",
    "\n",
    "ref: https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a009d7-cd0b-497a-8cc6-29594bf07c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def one_perceptron(X, y, W, b):\n",
    "def one_perceptron(x, y_truth, W, b):\n",
    "\n",
    "    # reshape x from (9,) to (9, 1)\n",
    "    #x = x.reshape(x.shape[0], 1)\n",
    "        \n",
    "    y_pred = x.T @ W + b # x.T.shape=(1, 9), W.shape=(9, 1)\n",
    "    y_pred = y_pred[0][0] # convert array to int\n",
    "    \n",
    "    # RMSD\n",
    "    c = (y_pred-y_truth)**2 # represents the distance between y_pred and y_truth for one perceptron\n",
    "    \n",
    "    #update the parameters\n",
    "    #dloss_dw = x * (y_pred-y_truth) #* 2\n",
    "    #dloss_db = 1 * (y_pred-y_truth) #* 2\n",
    "        \n",
    "    #W = W - lr * dloss_dw\n",
    "    #b = b - lr * dloss_db\n",
    "        \n",
    "    return y_pred, y_truth, c, #W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2e8730-5e4e-4f94-a404-46ac86bc918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred=-1.6000752536485336, y_truth=1, c=6.760391324635487\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_truth, c = one_perceptron(X[0].reshape(X[0].shape[0], 1), y[0], W, b)\n",
    "print(f\"y_pred={y_pred}, y_truth={y_truth}, c={c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3653700-97d3-4ccd-b73e-30beba8e87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z, derivative=False):\n",
    "    \n",
    "    if derivative == False:\n",
    "        y_sigma = 1 / (1+math.exp(-z))\n",
    "        \n",
    "    if derivative == True:\n",
    "        y_sigma = (1 / (1+math.exp(-z))) * (1 - (1 / (1+math.exp(-z))))\n",
    "        \n",
    "    return y_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9650ba70-01da-4891-9c78-6bc2f37c6b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13975680783398306"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sigma = sigmoid(y_pred, derivative=True)\n",
    "y_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd739cac-b40b-4718-bfdd-b5cfb38d5dcc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387aa65-5013-4807-8e1f-d9bd6e78c1f9",
   "metadata": {},
   "source": [
    "## training one batch\n",
    "\n",
    "We use N-folder cross validation technique. We set $N=5$ here, four folders for train and 1 folder for validation, then, repeat until every folder has been a validation folder. We obtain 5 hypothesis with the MSE score for each validation batch. We obtain the parameters (W, b) of the smallest MSE score of validation set and use them to train the whole training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a73fb-16e3-4e0d-a2ae-cd18d03cb1c7",
   "metadata": {},
   "source": [
    "$$\n",
    "MSE = \\frac{1}{N}\\times \\sum_{i=1}^{n}(Y_{i}-\\hat{Y_{i}})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89492a42-e9a6-42ab-9bf5-e87384f5d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(X, y, W, b): \n",
    "          \n",
    "    # set up some constants\n",
    "    loss_sum = 0.0\n",
    "    mse = 0.0\n",
    "    accuracy_sum = 0.0\n",
    "    accuracy_avg = 0.0\n",
    "    \n",
    "    for idx, x in enumerate(X):\n",
    "        \n",
    "        # reshape x from (9,) to (9, 1)\n",
    "        x = x.reshape(x.shape[0], 1)\n",
    "  \n",
    "        y_pred, y_truth, c = one_perceptron(x, y[idx], W, b)\n",
    "    \n",
    "        if c == 0:\n",
    "            accuracy_sum += 1\n",
    "                  \n",
    "        loss_sum += c\n",
    "        \n",
    "            \n",
    "        #update the parameters\n",
    "        dloss_dw = x * (y_pred-y_truth) #* 2\n",
    "        dloss_db = 1 * (y_pred-y_truth) #* 2\n",
    "        \n",
    "        W = W - lr * dloss_dw\n",
    "        b = b - lr * dloss_db\n",
    "\n",
    "\n",
    "    mse = loss_sum/len(X)\n",
    "    accuracy_avg = accuracy_sum/len(X)\n",
    "    \n",
    "    print(f\"loss_sum={loss_sum}, mse={mse}, \\\n",
    "    accuracy_sum={accuracy_sum}, accuracy_avg={accuracy_avg}\")\n",
    "    \n",
    "    return W, b, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d07b6f-a3a7-4d6b-9de0-afe193f70708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_sum=647.574839780206, mse=5.996063331298204,     accuracy_sum=0.0, accuracy_avg=0.0\n",
      "W1=(9, 1), b1=-0.3184974634156516, mse1=5.996063331298204\n"
     ]
    }
   ],
   "source": [
    "W1, b1, mse1 = train_one_batch(X, y, W, b)\n",
    "\n",
    "print(f\"W1={W1.shape}, b1={b1}, mse1={mse1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d901725-ab41-4a13-a7e0-e31530f57668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 5 batches of train/validation data \n",
    "for i in \n",
    "train_data = np.random.shuffle(train_data)\n",
    "train1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982450d-177c-44f8-b68b-2d6bd33006e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad85c3bb-eaa4-4fb0-9d26-2379877bc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(): # in this case, one epoch = 4 training folders and 1 validation set\n",
    "    \n",
    "    return W, b, validation_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb508543-9e1e-40ea-9498-e1a6228425a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
